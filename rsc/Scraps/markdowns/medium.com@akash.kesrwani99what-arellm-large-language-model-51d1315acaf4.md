# What are LLM(Large Language Model)?<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/da:true/resize:fill:88:88/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---byline--51d1315acaf4--------------------------------)<br><br>[Akash Kesrwani](/@akash.kesrwani99?source=post_page---byline--51d1315acaf4--------------------------------)<br><br>·<br><br>[Follow](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff2b8f3dd49c5&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&user=Akash+Kesrwani&userId=f2b8f3dd49c5&source=post_page-f2b8f3dd49c5--byline--51d1315acaf4---------------------post_header-----------)<br><br>9 min read<br><br>·<br><br>Jul 3, 2023<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&user=Akash+Kesrwani&userId=f2b8f3dd49c5&source=---header_actions--51d1315acaf4---------------------clap_footer-----------)<br><br>129<br><br>2<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&source=---header_actions--51d1315acaf4---------------------bookmark_footer-----------)<br><br>[Listen](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&source=---header_actions--51d1315acaf4---------------------post_audio_button-----------)<br><br>Share<br><br>**Large language models (LLMs)** are powerful machine-learning models that can understand and generate natural language. They are trained on massive datasets of text and code, which allows them to learn the patterns and relationships that exist in language. LLMs can be used for a variety of tasks, such as translating languages, analyzing sentiment, and generating creative text formats.<br><br>Here are some specific examples of what LLMs can do:<br><br>  * **Translate languages:** LLMs can be used to translate text from one language to another. For example, an LLM could be used to translate a French news article into English.<br>  * **Analyze sentiment:** LLMs can be used to analyze the sentiment of the text. For example, an LLM could be used to determine whether a customer review is positive or negative.<br>  * **Generate creative text formats:** LLMs can be used to generate creative text formats, such as poems, code, scripts, musical pieces, emails, letters, etc. For example, an LLM could be used to generate a poem about a particular topic.<br><br><br><br>## Learning Objectives<br><br>  * Understand the concept of Large Language Models (LLMs) and their importance in natural language processing.<br>  * Know about different types of popular LLMs, such as BERT, GPT-3, and T5.<br>  * Discuss the applications and use cases of Open Source LLMs.<br>  * Hugging Face APIs for LLMs.<br>  * Explore the future implications of LLMs, including their potential impact on job markets, communication, and society as a whole.<br><br><br><br>## **What is LLM?**<br><br>**A large language model (LLM) is a type of artificial intelligence (AI) that can generate human-like text and perform various natural language processing tasks**. LLMs are trained on massive amounts of text data, which allows them to learn the patterns and relationships that exist in language. This makes them capable of generating text that is often indistinguishable from that written by humans.<br><br>Here are some real-world examples of LLMs in action:<br><br>  * **Google Translate:** Google Translate uses an LLM to translate text from one language to another. The LLM is trained on a massive dataset of text and code, which allows it to learn the patterns and relationships that exist between different languages. This makes Google Translate one of the most accurate translation tools available.<br>  * **GPT-3** : GPT-3 is a large language model developed by OpenAI. GPT-3 is capable of generating human-like text, translating languages, and writing different kinds of creative content. It has been used to create a variety of applications, including chatbots, text generators, and creative writing tools.<br>  * **Bard:** Bard is a large language model developed by Google AI. Bard is capable of answering your questions in an informative way, even if they are open-ended, challenging, or strange. It can also generate different creative text formats of text content, like poems, code, scripts, musical pieces, emails, letters, etc.<br><br><br><br>## **How large language model(LLM) is built?**<br><br>Large language models (LLMs) are trained on massive amounts of text data. This data is used to teach the model the statistical relationships between words, phrases, and sentences. This allows the model to generate coherent and contextually relevant responses to prompts or queries.<br><br>LLMs are typically too large to run on a single computer, so they are provided as a service over an API or web interface. This means that you can access the model’s capabilities without having to download or install it yourself.<br><br>One example of an LLM is ChatGPT’s GPT-3 model. GPT-3 was trained on massive amounts of internet text data, which gave it the ability to understand various languages and possess knowledge of diverse topics. As a result, it can produce text in multiple styles.<br><br>While GPT-3’s capabilities may seem impressive, they are not surprising. This is because LLMs operate using special “grammar” that matches up with prompts. These grammars tell the model how to generate text that is relevant to the prompt.<br><br>**For example** , if you prompt GPT-3 to “** _write a poem about love,_** ” the model will use its grammar to generate text that is relevant to the prompt. The text will likely be in the form of a poem, and it will likely be about love.<br><br>## **General Architecture :**<br><br>The architecture of large language models (LLMs) is composed of multiple layers of neural networks. These layers include **_embedding layers, recurrent layers, feedforward layers, and attention layers_**. Each layer helps the model process the input text and generate output predictions.<br><br>The**_embedding layer_** converts each word in the input text into a high-dimensional vector representation. This representation captures semantic and syntactic information about the word, which helps the model understand the context.<br><br>The** _feedforward layers_** apply nonlinear transformations to the input embeddings. This helps the model learn higher-level abstractions from the input text.<br><br>The**_recurrent layers_** interpret information from the input text in sequence. They maintain a hidden state that is updated at each time step, allowing the model to capture the dependencies between words in a sentence.<br><br>The **_attention mechanism_** allows the model to focus selectively on different parts of the input text. This helps the model attend to the input text’s most relevant parts and generate more accurate predictions.<br><br>**In summary** , the architecture of LLMs is designed to process the input text in a way that captures the meaning of the text and the relationships between words. This allows the model to generate accurate predictions.<br><br>**Example :** Here are some examples of popular large language models (LLMs):<br><br>  * **GPT-3:** Developed by OpenAI, GPT-3 is one of the largest LLMs with 175 billion parameters. It can perform many tasks, including text generation, translation, and summarization.<br>  * **BERT:** Developed by Google, BERT is another popular LLM that has been trained on a massive corpus of text data. It can understand the context of a sentence and generate meaningful responses to questions.<br>  * **XLNet:** Developed by Carnegie Mellon University and Google, XLNet uses a novel approach to language modeling called “permutation language modeling.” It has achieved state-of-the-art performance on language tasks, including language generation and question answering.<br>  * **T5:** Developed by Google, T5 is trained on a variety of language tasks and can perform text-to-text transformations, like translating text to another language, creating a summary, and question answering.<br>  * **RoBERTa:** Developed by Facebook AI Research, RoBERTa is an improved BERT version that performs better on several language tasks.<br><br><br><br># **Open Source Language Model :**<br><br>Open-source LLMs have made it possible for researchers, developers, and businesses to build applications that leverage the power of these models. Bloom is an example of an open-source LLM that has been trained on a massive dataset of text data. It has 176 billion parameters, making it larger than OpenAI’s GPT-3. Bloom can generate text in **46** natural languages and 13 programming languages. It is a powerful tool that can be used for a variety of applications, including text generation, translation, and question-answering.<br><br>Here are some specific examples of how Bloom can be used:<br><br>  * **Text generation:** Bloom can be used to generate text in a variety of styles, including creative writing, code, and scripts.<br>  * **Translation:** Bloom can be used to translate text from one language to another.<br>  * **Question answering:** Bloom can be used to answer questions about a variety of topics.<br><br><br><br>**Bloom Architecture:**<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*I53B51aS87TFbcsc5CookQ.png)<br><br>Bloom’s architecture is similar to GPT-3, but it has been trained in a wider range of languages. It consists of a decoder-only architecture with several embedding layers and multi-headed attention layers. This architecture makes it well-suited for training in multiple languages and allows users to translate and talk about a topic in a different language.<br><br>Here are some examples of how _Bloom’s_ architecture can be used:<br><br>  * **Translation:** Bloom can be used to translate text from one language to another. For example, if you wanted to translate the sentence **_“I love you”_** from English to French, you could use Bloom to generate the French sentence **_“Je t’aime.”_**<br>  * **Multilingual conversation:** Bloom can be used to have a conversation in multiple languages. For example, if you were talking to someone who spoke French and English, you could use Bloom to generate text in both languages.<br><br><br><br>**Other LLMs**<br><br>We can utilize the APIs connected to pre-trained models of many of the widely available LLMs through Hugging Face<br><br>## Hugging Face API<br><br>Let’s look into how Hugging Face APIs can help generate text using LLMs like Bloom, Roberta-base, etc. First, we need to sign up for Hugging Face and copy the token for API access. After signup, hover over to the profile icon on the top right, click on settings, and then Access Tokens.<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*Iy6gWBzLVo1dhSgnWo-z0w.png)<br><br>Large Language Models (LLMs) are foundational machine learning models that use deep learning algorithms to process and understand natural language. These models are trained on massive amounts of text data to learn patterns and entity relationships in the language. LLMs can perform many types of language tasks, such as translating languages, analyzing sentiments, chatbot conversations, and more. They can understand complex textual data, identify entities and relationships between them, and generate new text that is coherent and grammatically accurate.<br><br># **Example 1: Sentence Completion**<br><br>Let’s look at how we can use Bloom for sentence completion. The code below uses the hugging face token for API to send an API call with the input text and appropriate parameters for getting the best response.<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*wlPlXyNAYCBGSiQfwM6aRQ.png)<br><br>Temperature and top_k values can be modified to get a larger or smaller paragraph while maintaining the relevance of the generated text to the original input text. We get the following output from the code:<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*ZNHZhpdglqiEIiiBY7fk-w.png)<br><br># Example 2: Question Answers<br><br>We can use the API for the Roberta-base model which can be a source to refer to and reply to. Let’s change the payload to provide some information about myself and ask the model to answer questions based on that.<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*0dhUBHVllzPNjxt2gm1k-A.png)<br><br>The code prints the below output correctly to the question — What is my profession?:<br><br>![](https://miro.medium.com/v2/resize:fit:700/1*ka9q9drJMxF_3aXzOf6MgQ.png)<br><br># **Future Implications of LLM :**<br><br>LLMs, such as GPT-3, are a breakthrough in AI. However, there are concerns about their impact on job markets, communication, and society. One concern is that LLMs could automate jobs, leading to job losses. However, LLMs could also create new jobs and help businesses and governments make better decisions. Overall, LLMs have the potential to have a significant impact on society. It is important to carefully consider the potential risks and benefits of these models before they are widely adopted.<br><br>Here are some specific examples of how LLMs could impact society:<br><br>  * **Education:** LLMs could be used to create personalized education plans for students, tailored to their individual needs and learning styles. This could help students to learn more effectively and achieve their full potential.<br>  * **Healthcare:** LLMs could be used to create personalized healthcare plans for patients, based on their individual medical history and needs. This could help patients to receive the best possible care.<br>  * **Business:** LLMs could be used to help businesses make better decisions by analyzing large amounts of data and generating insights. This could help businesses to improve their products and services and to make more informed decisions about their operations.<br><br><br><br># **Conclusion :**<br><br>Large Language Models (LLMs) have revolutionized the field of natural language processing, allowing for new advancements in text generation and understanding. LLMs can learn from big data, understand its context and entities, and answer user queries. This makes them a great alternative for regular usage in various tasks in several industries. However, there are concerns about the ethical implications and potential biases associated with these models. It is important to approach LLMs with a critical eye and evaluate their impact on society. With careful use and continued development, LLMs have the potential to bring about positive changes in many domains, but we should be aware of their limitations and ethical implications.<br><br>**_Thanks!_**<br><br>[ Llm](/tag/llm?source=post_page-----51d1315acaf4--------------------------------)<br><br>[AI](/tag/ai?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Gpt 3 Openai](/tag/gpt-3-openai?source=post_page-----51d1315acaf4--------------------------------)<br><br>[NLP](/tag/nlp?source=post_page-----51d1315acaf4--------------------------------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&user=Akash+Kesrwani&userId=f2b8f3dd49c5&source=---footer_actions--51d1315acaf4---------------------clap_footer-----------)<br><br>129<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&user=Akash+Kesrwani&userId=f2b8f3dd49c5&source=---footer_actions--51d1315acaf4---------------------clap_footer-----------)<br><br>129<br><br>2<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F51d1315acaf4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&source=---footer_actions--51d1315acaf4---------------------bookmark_footer-----------)<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/resize:fill:96:96/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---post_author_info--51d1315acaf4--------------------------------)<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/resize:fill:128:128/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---post_author_info--51d1315acaf4--------------------------------)<br><br>Follow<br><br>## [Written by Akash Kesrwani](/@akash.kesrwani99?source=post_page---post_author_info--51d1315acaf4--------------------------------)<br><br>[48 Followers](/@akash.kesrwani99/followers?source=post_page---post_author_info--51d1315acaf4--------------------------------)<br><br>·[13 Following](/@akash.kesrwani99/following?source=post_page---post_author_info--51d1315acaf4--------------------------------)<br><br>Follow<br><br>## Responses (2)<br><br>[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--51d1315acaf4--------------------------------)<br><br>[What are your thoughts?](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fwhat-arellm-large-language-model-51d1315acaf4&source=---post_responses--51d1315acaf4---------------------respond_sidebar-----------)<br><br>Cancel<br><br>Respond<br><br>Also publish to my profile<br><br>![Makleas](https://miro.medium.com/v2/resize:fill:32:32/1*wdvELl3p-T_I-hlwycuYLw.png)<br><br>[Makleas](/@Makleas?source=post_page---post_responses--51d1315acaf4----0----------------------------)<br><br>[over 1 year ago](/@Makleas/informative-content-a80a831c18c?source=post_page---post_responses--51d1315acaf4----0----------------------------)<br><br>```<br><br><br>Informative content!<br><br><br>```<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa80a831c18c&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40Makleas%2Finformative-content-a80a831c18c&user=Makleas&userId=3521e471a181&source=---post_responses--a80a831c18c----0-----------------respond_sidebar-----------)<br><br>4<br><br>Reply<br><br>![Rahul Rchoudhury](https://miro.medium.com/v2/resize:fill:32:32/0*W2HFDimYP0ubIt_i)<br><br>[Rahul Rchoudhury](/@rahul.rchoudhury922?source=post_page---post_responses--51d1315acaf4----1----------------------------)<br><br>[about 1 year ago](/@rahul.rchoudhury922/nicely-explained-e7338797a78d?source=post_page---post_responses--51d1315acaf4----1----------------------------)<br><br>```<br><br><br>Nicely Explained!<br><br><br>```<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fe7338797a78d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40rahul.rchoudhury922%2Fnicely-explained-e7338797a78d&user=Rahul+Rchoudhury&userId=dfe7a903cae3&source=---post_responses--e7338797a78d----1-----------------respond_sidebar-----------)<br><br>1<br><br>Reply<br><br>## More from Akash Kesrwani<br><br>![Understanding Next Token Prediction: Concept To Code: 1st part!](https://miro.medium.com/v2/resize:fit:679/0*OvRah47L6Mg_xUc6.png)<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/resize:fill:20:20/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----0---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[Akash Kesrwani](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----0---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>## [Understanding Next Token Prediction: Concept To Code: 1st part!Note: We’re going to develop a deep-dive understanding of the mechanism of the next token Prediction with all concepts & code. I just Break…](/@akash.kesrwani99/understanding-next-token-prediction-concept-to-code-1st-part-7054dabda347?source=post_page---author_recirc--51d1315acaf4----0---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>Sep 8, 2023<br><br>[951](/@akash.kesrwani99/understanding-next-token-prediction-concept-to-code-1st-part-7054dabda347?source=post_page---author_recirc--51d1315acaf4----0---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7054dabda347&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Funderstanding-next-token-prediction-concept-to-code-1st-part-7054dabda347&source=---author_recirc--51d1315acaf4----0-----------------bookmark_preview----2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>![Multi-Head Self Attention: Short Understanding](https://miro.medium.com/v2/resize:fit:679/0*tbWezLEMcagQpDHs)<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/resize:fill:20:20/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----1---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[Akash Kesrwani](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----1---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>## [Multi-Head Self Attention: Short UnderstandingEach “block” of a large language model (LLM) is comprised of self-attention and a feed-forward transformation. However, the exact…](/@akash.kesrwani99/multi-head-self-attention-short-understanding-e90a34866730?source=post_page---author_recirc--51d1315acaf4----1---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>Sep 8, 2023<br><br>[762](/@akash.kesrwani99/multi-head-self-attention-short-understanding-e90a34866730?source=post_page---author_recirc--51d1315acaf4----1---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe90a34866730&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fmulti-head-self-attention-short-understanding-e90a34866730&source=---author_recirc--51d1315acaf4----1-----------------bookmark_preview----2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>![German to English Translation using Seq2Seq](https://miro.medium.com/v2/resize:fit:679/1*pQ2tm6Mirdrf6hqwfYXb0g.gif)<br><br>[![Akash Kesrwani](https://miro.medium.com/v2/resize:fill:20:20/0*kJvciUT0ZQv04P3w)](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----2---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[Akash Kesrwani](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4----2---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>## [How do Transformers work in NLP?Overview](/@akash.kesrwani99/how-do-transformers-work-in-nlp-50997d22a253?source=post_page---author_recirc--51d1315acaf4----2---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>Aug 14, 2023<br><br>[83](/@akash.kesrwani99/how-do-transformers-work-in-nlp-50997d22a253?source=post_page---author_recirc--51d1315acaf4----2---------------------2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F50997d22a253&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40akash.kesrwani99%2Fhow-do-transformers-work-in-nlp-50997d22a253&source=---author_recirc--51d1315acaf4----2-----------------bookmark_preview----2e6dfbc9_0c7c_4361_9e39_c5001fe53367-------)<br><br>[See all from Akash Kesrwani](/@akash.kesrwani99?source=post_page---author_recirc--51d1315acaf4--------------------------------)<br><br>## Recommended from Medium<br><br>![LLM Architectures Explained: NLP Fundamentals \(Part 1\)](https://miro.medium.com/v2/resize:fit:679/0*TH7ixPJypLQTLtLf.png)<br><br>[![Vipra Singh](https://miro.medium.com/v2/resize:fill:20:20/1*LDjQS3c-G1gsojOf24ijGg@2x.jpeg)](/@vipra_singh?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[Vipra Singh](/@vipra_singh?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [LLM Architectures Explained: NLP Fundamentals (Part 1)Deep Dive into the architecture & building of real-world applications leveraging NLP Models starting from RNN to the Transformers.](/@vipra_singh/llm-architectures-explained-nlp-fundamentals-part-1-de5bf75e553a?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>Aug 15, 2024<br><br>[2.1K16](/@vipra_singh/llm-architectures-explained-nlp-fundamentals-part-1-de5bf75e553a?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde5bf75e553a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vipra_singh%2Fllm-architectures-explained-nlp-fundamentals-part-1-de5bf75e553a&source=---read_next_recirc--51d1315acaf4----0-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>![A Brief History of AI with Deep Learning](https://miro.medium.com/v2/resize:fit:679/1*1QuqK5gcXloiZAkhr-_QOA.png)<br><br>[![LM Po](https://miro.medium.com/v2/resize:fill:20:20/1*8biNIOdTZO6v4MDdtPmm2Q.png)](/@lmpo?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[LM Po](/@lmpo?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [A Brief History of AI with Deep LearningArtificial intelligence (AI) and deep learning have seen remarkable progress over the past several decades, transforming fields like…](/@lmpo/a-brief-history-of-ai-with-deep-learning-26f7948bc87b?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>Sep 1, 2024<br><br>[4237](/@lmpo/a-brief-history-of-ai-with-deep-learning-26f7948bc87b?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26f7948bc87b&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40lmpo%2Fa-brief-history-of-ai-with-deep-learning-26f7948bc87b&source=---read_next_recirc--51d1315acaf4----1-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## Lists<br><br>[![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*1slEF5nrsmkF4JwU)![](https://miro.medium.com/v2/resize:fill:48:48/1*Am5tPc909zaR2j6o_EvjrA.png)![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*PUm2ZQi0LLE7TD6a)Natural Language Processing1884 stories·1527 saves](/@AMGAS14/list/natural-language-processing-0a856388a93a?source=post_page---read_next_recirc--51d1315acaf4--------------------------------)<br><br>[![Image by vectorjuice on FreePik](https://miro.medium.com/v2/resize:fill:48:48/0*3OsUtsnlTx9Svm4c.jpg)![](https://miro.medium.com/v2/resize:fill:48:48/1*IPZF1hcDWwpPqOz2vL7NxQ.png)![](https://miro.medium.com/v2/resize:fill:48:48/1*0fHUKyg3xtpNWpop35PR4g.png)The New Chatbots: ChatGPT, Bard, and Beyond12 stories·534 saves](/@MediumStaff/list/the-new-chatbots-chatgpt-bard-and-beyond-5969c7449b7f?source=post_page---read_next_recirc--51d1315acaf4--------------------------------)<br><br>[![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*M8Jq6btD0YsgaRM1)![](https://miro.medium.com/v2/resize:fill:48:48/1*rsp22rKwFDjiwwCcUly56Q.jpeg)![](https://miro.medium.com/v2/resize:fill:48:48/1*PNVLDmurJ5LoCjB9Ovdnpw.png)Generative AI Recommended Reading52 stories·1588 saves](https://tomsmith585.medium.com/list/generative-ai-recommended-reading-508b0743c247?source=post_page---read_next_recirc--51d1315acaf4--------------------------------)<br><br>[![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*_eYHSSUS0abUxmDU)![](https://miro.medium.com/v2/resize:fill:48:48/1*wXgeNtz5OJ5O9T3c3mQRRw.png)![](https://miro.medium.com/v2/resize:fill:48:48/0*tIipcmrInD5UMpQI.png)What is ChatGPT?9 stories·491 saves](/@MediumForTeams/list/what-is-chatgpt-7a5756752f49?source=post_page---read_next_recirc--51d1315acaf4--------------------------------)<br><br>![I used OpenAI’s o1 model to develop a trading strategy. It is DESTROYING the market](https://miro.medium.com/v2/resize:fit:679/1*MuD60qiJYZ1GJSSraELZpg.png)<br><br>[![DataDrivenInvestor](https://miro.medium.com/v2/resize:fill:20:20/1*2mBCfRUpdSYRuf9EKnhTDQ.png)](https://medium.com/datadriveninvestor?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>In<br><br>[DataDrivenInvestor](https://medium.com/datadriveninvestor?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>by<br><br>[Austin Starks](/@austin-starks?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [I used OpenAI’s o1 model to develop a trading strategy. It is DESTROYING the marketIt literally took one try. I was shocked.](/datadriveninvestor/i-used-openais-o1-model-to-develop-a-trading-strategy-it-is-destroying-the-market-576a6039e8fa?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>Sep 15, 2024<br><br>[8.2K206](/datadriveninvestor/i-used-openais-o1-model-to-develop-a-trading-strategy-it-is-destroying-the-market-576a6039e8fa?source=post_page---read_next_recirc--51d1315acaf4----0---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F576a6039e8fa&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fi-used-openais-o1-model-to-develop-a-trading-strategy-it-is-destroying-the-market-576a6039e8fa&source=---read_next_recirc--51d1315acaf4----0-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>![4 ideas that are changing the game for LLM research](https://miro.medium.com/v2/resize:fit:679/0*wEZdAYbh2DpfFSJG)<br><br>[![AI Advances](https://miro.medium.com/v2/resize:fill:20:20/1*R8zEd59FDf0l8Re94ImV0Q.png)](https://medium.com/ai-advances?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>In<br><br>[AI Advances](https://medium.com/ai-advances?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>by<br><br>[Nikhil Anand](/@nikhilanandnj?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [4 ideas that are changing the game for LLM researchThe 2nd got me a full-time job at Adobe.](/ai-advances/4-ideas-that-are-changing-the-game-for-llm-research-aec86098e429?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>5d ago<br><br>[2683](/ai-advances/4-ideas-that-are-changing-the-game-for-llm-research-aec86098e429?source=post_page---read_next_recirc--51d1315acaf4----1---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faec86098e429&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2F4-ideas-that-are-changing-the-game-for-llm-research-aec86098e429&source=---read_next_recirc--51d1315acaf4----1-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>![A Very Gentle Introduction to Large Language Models without the Hype](https://miro.medium.com/v2/resize:fit:679/1*n7WcunMeetLgrf8WezNKwg.jpeg)<br><br>[![Mark Riedl](https://miro.medium.com/v2/resize:fill:20:20/1*mDI01u7cqzQfHdg377DIDA.png)](/@mark-riedl?source=post_page---read_next_recirc--51d1315acaf4----2---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[Mark Riedl](/@mark-riedl?source=post_page---read_next_recirc--51d1315acaf4----2---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [A Very Gentle Introduction to Large Language Models without the Hype1. Introduction](/@mark-riedl/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=post_page---read_next_recirc--51d1315acaf4----2---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>Apr 13, 2023<br><br>[8.1K131](/@mark-riedl/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=post_page---read_next_recirc--51d1315acaf4----2---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f67941fa59e&operation=register&redirect=https%3A%2F%2Fmark-riedl.medium.com%2Fa-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e&source=---read_next_recirc--51d1315acaf4----2-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>![Building LLaMA 3 From Scratch with Python](https://miro.medium.com/v2/resize:fit:679/1*BA7OcKmY62jt1UaF4B424Q.jpeg)<br><br>[![Level Up Coding](https://miro.medium.com/v2/resize:fill:20:20/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://medium.com/gitconnected?source=post_page---read_next_recirc--51d1315acaf4----3---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>In<br><br>[Level Up Coding](https://medium.com/gitconnected?source=post_page---read_next_recirc--51d1315acaf4----3---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>by<br><br>[Fareed Khan](/@fareedkhandev?source=post_page---read_next_recirc--51d1315acaf4----3---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>## [Building LLaMA 3 From Scratch with PythonCode Your Own Billion Parameter LLM](/gitconnected/building-llama-3-from-scratch-with-python-e0cf4dbbc306?source=post_page---read_next_recirc--51d1315acaf4----3---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>May 28, 2024<br><br>[1.7K17](/gitconnected/building-llama-3-from-scratch-with-python-e0cf4dbbc306?source=post_page---read_next_recirc--51d1315acaf4----3---------------------c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe0cf4dbbc306&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fbuilding-llama-3-from-scratch-with-python-e0cf4dbbc306&source=---read_next_recirc--51d1315acaf4----3-----------------bookmark_preview----c7db2659_7209_4d9d_a0c7_db5946999d76-------)<br><br>[See more recommendations](/?source=post_page---read_next_recirc--51d1315acaf4--------------------------------)<br><br>[Help](https://help.medium.com/hc/en-us?source=post_page-----51d1315acaf4--------------------------------)<br><br>[About](/about?autoplay=1&source=post_page-----51d1315acaf4--------------------------------)<br><br>[Careers](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Press](pressinquiries@medium.com?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Blog](https://blog.medium.com/?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----51d1315acaf4--------------------------------)<br><br>[Teams](/business?source=post_page-----51d1315acaf4--------------------------------)<br><br>El reCAPTCHA requereix verificació. <br><br>- <br><br>protegit amb **reCAPTCHA**<br><br>- <br>